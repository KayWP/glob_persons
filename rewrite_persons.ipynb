{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87024ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from dataclasses import dataclass, field, fields\n",
    "from typing import Optional, List\n",
    "import copy\n",
    "from datetime import datetime  # For vali_date method\n",
    "\n",
    "# Third-party dependencies\n",
    "import pandas as pd  # For to_csv method\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import mapper, sessionmaker\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from tqdm import tqdm  # For progress bar in update_db method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PersonAttribute:\n",
    "    \"\"\"Base class for observation-related entities.\"\"\"\n",
    "    id: Optional[int] = None\n",
    "    observation_id: Optional[str] = None\n",
    "    reconstruction_id: Optional[str] = None\n",
    "    original_label: Optional[str] = None\n",
    "    annotationDate: Optional[str] = None\n",
    "    startDate: Optional[str] = None\n",
    "    endDate: Optional[str] = None\n",
    "    startDate_min: Optional[str] = None\n",
    "    startDate_max: Optional[str] = None\n",
    "    endDate_min: Optional[str] = None\n",
    "    endDate_max: Optional[str] = None\n",
    "    observation_source: Optional[str] = None\n",
    "    location_in_observation_source: Optional[str] = None\n",
    "    reconstruction_source: Optional[str] = None\n",
    "    location_in_reconstruction_source: Optional[str] = None\n",
    "    comment: Optional[str] = None\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        # First, lowercase all string fields except original_label\n",
    "        self._lowercase_string_fields()\n",
    "        \n",
    "        #validate dates after initialization\n",
    "        date_fields = [\n",
    "            \"annotationDate\", \"startDate\", \"endDate\", \"startDate_min\", \"startDate_max\", \"endDate_min\", \"endDate_max\"            \n",
    "        ]\n",
    "        \n",
    "        for field_name in date_fields:\n",
    "            date_value = getattr(self, field_name)\n",
    "            \n",
    "            if date_value == '-1':\n",
    "                setattr(self, field_name, None)\n",
    "            elif date_value is not None and not self.vali_date(date_value):\n",
    "                raise ValueError(\n",
    "                    f'Field {field_name} with value \"{date_value}\" is invalid. '\n",
    "                    'Only a valid date following the ISO 8601 standard can be used. '\n",
    "                    'It can be yyyy, yyyy-mm, or yyyy-mm-dd, or -1 for unknown dates.'\n",
    "                )\n",
    "    \n",
    "    def _lowercase_string_fields(self):\n",
    "        \"\"\"Convert all string field values to lowercase except original_label.\"\"\"\n",
    "        # Get all fields for this instance's class\n",
    "        class_fields = fields(self)\n",
    "        \n",
    "        # Process each field\n",
    "        for field in class_fields:\n",
    "            value = getattr(self, field.name)\n",
    "            \n",
    "            # Skip None values and original_label field\n",
    "            if value is None or field.name == 'original_label':\n",
    "                continue\n",
    "                \n",
    "            # Convert string values to lowercase\n",
    "            if isinstance(value, str) and value:\n",
    "                setattr(self, field.name, value.lower())\n",
    "    \n",
    "    @staticmethod\n",
    "    def vali_date(date_string: str) -> bool:\n",
    "        \"\"\"\n",
    "        Validates if a string is a proper date format.\n",
    "        Accepts:\n",
    "        - ISO 8601 format: yyyy, yyyy-mm, or yyyy-mm-dd\n",
    "        \n",
    "        Args:\n",
    "            date_string: The string to validate\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if valid, False otherwise\n",
    "        \"\"\"\n",
    "            \n",
    "        formats = [\"%Y\", \"%Y-%m\", \"%Y-%m-%d\"]\n",
    "        \n",
    "        for format_string in formats:\n",
    "            try:\n",
    "                datetime.strptime(date_string, format_string)\n",
    "                return True\n",
    "            except ValueError:\n",
    "                continue  # Try the next format\n",
    "            except TypeError:\n",
    "                return False  # date_string is not a string\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fba5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PersonAttributeLocation(PersonAttribute):\n",
    "    \"\"\"Adds location based methods to PersonAttribute\"\"\"\n",
    "    location: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0025e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Appellation(PersonAttribute):\n",
    "    \"\"\"Represents an appellation associated with a person.\"\"\"\n",
    "    appellation: Optional[str] = None\n",
    "    appellationType: Optional[str] = None\n",
    "    toponym: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdf8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ActiveAs(PersonAttributeLocation):\n",
    "    \"\"\"Represents an activity associated with a person.\"\"\"\n",
    "    activity: Optional[str] = None\n",
    "    activityType: Optional[str] = None\n",
    "    employer: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528e9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Identity(PersonAttributeLocation):\n",
    "    \"\"\"Represents an identity associated with a person.\"\"\"\n",
    "    identity: Optional[str] = None\n",
    "    identityType: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b675e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Status(PersonAttributeLocation):\n",
    "    \"\"\"Represents a status associated with a person.\"\"\"\n",
    "    status: Optional[str] = None\n",
    "    statusType: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe727a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LocationRelation(PersonAttributeLocation):\n",
    "    \"\"\"Represents a location relation associated with a person.\"\"\"\n",
    "    locationRelation: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d548e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Relation(PersonAttribute):\n",
    "    \"\"\"Represents a relation between two people.\"\"\"\n",
    "    relation: Optional[str] = None\n",
    "    otherPerson: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54dbd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Event(PersonAttributeLocation):\n",
    "    \"\"\"Represents an event associated with a person.\"\"\"\n",
    "    event: Optional[str] = None\n",
    "    argument: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e15c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExternalReference:\n",
    "    \"\"\"Represents an external reference to a person in another database.\"\"\"\n",
    "    id: Optional[int] = None\n",
    "    URI: str = \"\"\n",
    "    reconstruction_id: Optional[str] = None\n",
    "    external_db_name: Optional[str] = None\n",
    "    external_id: Optional[str] = None\n",
    "    external_id_type: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fe4cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Person:\n",
    "    \"\"\"Represents a person entity.\"\"\"\n",
    "    id: Optional[int] = None\n",
    "    URI: str = \"\"\n",
    "    comment: Optional[str] = None\n",
    "    \n",
    "    # Relationships (populated after initialization)\n",
    "    active_as: List[ActiveAs] = field(default_factory=list)\n",
    "    appellations: List[Appellation] = field(default_factory=list)\n",
    "    identities: List[Identity] = field(default_factory=list)\n",
    "    statuses: List[Status] = field(default_factory=list)\n",
    "    location_relations: List[LocationRelation] = field(default_factory=list)\n",
    "    relations: List[Relation] = field(default_factory=list)\n",
    "    events: List[Event] = field(default_factory=list)\n",
    "    external_references: List[ExternalReference] = field(default_factory=list)\n",
    "    \n",
    "    def split_values(self, attribute_name: str, field_name: str, separators: List[str], unused_remains: List[str], exceptions: List[str]):\n",
    "        \"\"\"\n",
    "        Splits values in a specified field of PersonAttribute instances into multiple instances,\n",
    "        using defined separators. Filters out unwanted values and respects exception list.\n",
    "        \n",
    "        Args:\n",
    "            attribute_name: Name of the list of PersonAttribute instances (e.g. 'active_as')\n",
    "            field_name: Name of the field in those instances to split (e.g. 'location')\n",
    "            separators: List of substrings to split the value on\n",
    "            unused_remains: List of split values to ignore/remove\n",
    "            exceptions: List of full values that should not be split\n",
    "        \"\"\"\n",
    "        \n",
    "        #first check if it is a valid request\n",
    "        attr_list = getattr(self, attribute_name, None)\n",
    "        if not isinstance(attr_list, list):\n",
    "            raise AttributeError(f\"{attribute_name} is not a valid Person Attribute\")\n",
    "        \n",
    "        #then check if there is anything in the list\n",
    "        if not attr_list:\n",
    "            return\n",
    "        \n",
    "        #then check if the field value is legit\n",
    "        if not hasattr(attr_list[0], field_name):\n",
    "            raise AttributeError(f\"{field_name} is not a valid field for {attribute_name}\")\n",
    "        \n",
    "        #make a new list\n",
    "        new_p_attrs = []\n",
    "        \n",
    "        #check against exceptions\n",
    "        for a in attr_list:\n",
    "            value = getattr(a, field_name)\n",
    "            if not value or value.strip() in exceptions:\n",
    "                new_p_attrs.append(a)\n",
    "                continue\n",
    "        \n",
    "            #split\n",
    "            split_parts = [value]\n",
    "            \n",
    "            for sep in separators:\n",
    "                split_parts = [part.strip() for val in split_parts for part in val.split(sep)]\n",
    "                \n",
    "            # Filter out unused_remains\n",
    "            split_parts = [part for part in split_parts if part and part not in unused_remains]    \n",
    "\n",
    "            #for every split do a deepcopy, alter and append\n",
    "            if len(split_parts) <= 1:\n",
    "                new_p_attrs.append(a)\n",
    "                \n",
    "            else:\n",
    "                for part in split_parts:\n",
    "                    new_attr = copy.deepcopy(a)\n",
    "                    setattr(new_attr, field_name, part)\n",
    "                    new_p_attrs.append(new_attr)\n",
    "        \n",
    "        #replace old with new\n",
    "        setattr(self, attribute_name, new_p_attrs)\n",
    "        \n",
    "    \n",
    "    def link_values(self, mapping: dict, attribute_name: str, field_name: str, log_file: str = \"unmatched_values.txt\"):\n",
    "        \"\"\"\n",
    "        Replaces values in a specified attribute, in a specifiec field, with the mapped values in a dictionary.\n",
    "        Logs any keyerrors to a file.\n",
    "        \n",
    "        Args:\n",
    "            mapping: a dictionary containing key:value pairs linking a string to an URI or other external identifier.\n",
    "            attribute_name: the person attribute (e.g. appellation, or activeAs) that you want to link a value in\n",
    "            field_name: the field within the attribute (e.g. activity, or location, or appellationType) that \n",
    "            you want to link using the dict\n",
    "            log_file: where key errors will be logged as they need a future mapping\n",
    "        \"\"\"\n",
    "        \n",
    "        #first check if it is a valid request\n",
    "        attr_list = getattr(self, attribute_name, None)\n",
    "        if not isinstance(attr_list, list):\n",
    "            raise AttributeError(f\"{attribute_name} is not a valid Person Attribute\")\n",
    "        \n",
    "        #then check if there is anything in the list\n",
    "        if not attr_list:\n",
    "            return\n",
    "        \n",
    "        #then check if the field value is legit\n",
    "        if not hasattr(attr_list[0], field_name):\n",
    "            raise AttributeError(f\"{field_name} is not a valid field for {attribute_name}\")\n",
    "        \n",
    "        unmatched = set()\n",
    "        \n",
    "        for attr in attr_list:\n",
    "            current_value = getattr(attr, field_name)\n",
    "            if current_value in mapping:\n",
    "                setattr(attr, field_name, mapping[current_value])\n",
    "            elif current_value is not None:\n",
    "                unmatched.add(current_value)\n",
    "                \n",
    "        if unmatched:\n",
    "            with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                for val in unmatched:\n",
    "                    f.write(\"{val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce5963d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PersonList:\n",
    "    \"\"\"A dataclass representing a list of Person objects with utility methods.\"\"\"\n",
    "    #default factory just initiates an empty list\n",
    "    persons: List[Person] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        #validate that all items in the list are Person objects\n",
    "        if not all(isinstance(a, Person) for a in self.persons):\n",
    "            raise TypeError(\"This object must consist of a list of Person objects\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _format_value(value):\n",
    "        \"\"\"convert None values to '-1 for CSV export\"\"\"\n",
    "        return '-1' if value is None else value\n",
    "    \n",
    "    def split_list_valuessplit_values(self, attribute_name: str, field_name: str, separators: List[str], unused_remains: List[str], exceptions: List[str]):\n",
    "        for p in self.persons:\n",
    "            p.link_valuessplit_values(self, attribute_name, field_name, separators, unused_remains, exceptions)\n",
    "    \n",
    "    def link_list_values(self, mapping: dict, attribute_name: str, field_name: str, log_file: str = \"unmatched_values.txt\"):\n",
    "        \"\"\"\n",
    "        Replaces values in a specified attribute, in a specifiec field, with the mapped values in a dictionary.\n",
    "        Logs any keyerrors to a file.\n",
    "        \n",
    "        Args:\n",
    "            mapping: a dictionary containing key:value pairs linking a string to an URI or other external identifier.\n",
    "            attribute_name: the person attribute (e.g. appellation, or activeAs) that you want to link a value in\n",
    "            field_name: the field within the attribute (e.g. activity, or location, or appellationType) that \n",
    "            you want to link using the dict\n",
    "            log_file: where key errors will be logged that need to get a mapping\n",
    "        \"\"\"\n",
    "        \n",
    "        for p in self.persons:\n",
    "            p.link_values(mapping, attribute_name, field_name, log_file)\n",
    "    \n",
    "    def to_csv(self, makeOverview=True, makeAppellations=True, makeActive_as=True, makeIdentities=True, makeStatuses=True, makeLocation_relations=True, makeRelations=True, makeEvents=True, makeExternalReferences=True):\n",
    "        \"\"\"\n",
    "        Export person data to CSV files.\n",
    "\n",
    "        Parameters:\n",
    "        - makeOverview: Whether to create an overview CSV with basic person data\n",
    "        - makeAppellations: Whether to create a CSV with appellation data\n",
    "        - makeActive_as: Whether to create a CSV with activity data\n",
    "        - makeIdentities: Whether to create a CSV with identity data\n",
    "        - makeStatuses: Whether to create a CSV with status data\n",
    "        - makeLocation_relations: Whether to create a CSV with location relation data\n",
    "        - makeRelations: Whether to create a CSV with relation data\n",
    "        - makeEvents: Whether to create a CSV with event data\n",
    "        - makeExternalReferences: Whether to create a CSV with external reference data\n",
    "    \"\"\"\n",
    "    \n",
    "        if makeOverview:\n",
    "\n",
    "            overviewFrame = []\n",
    "\n",
    "            for p in self.persons:\n",
    "                overviewFrame.append([p.URI, self._format_value(p.comment)])\n",
    "            overviewFrame = pd.DataFrame(overviewFrame, columns=['URI', 'Comment'])\n",
    "            overviewFrame.to_csv('overview.csv')\n",
    "\n",
    "        if makeAppellations:\n",
    "            appellationsFrame = []\n",
    "            for p in self.persons:\n",
    "                for a in p.appellations:\n",
    "                    appellationsFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(a.observation_id),\n",
    "                        self._format_value(a.reconstruction_id),\n",
    "                        self._format_value(a.appellation),\n",
    "                        self._format_value(a.appellationType),\n",
    "                        self._format_value(a.annotationDate),\n",
    "                        self._format_value(a.startDate),\n",
    "                        self._format_value(a.endDate),\n",
    "                        self._format_value(a.startDate_min),\n",
    "                        self._format_value(a.startDate_max),\n",
    "                        self._format_value(a.endDate_min),\n",
    "                        self._format_value(a.endDate_max),\n",
    "                        self._format_value(a.toponym),\n",
    "                        self._format_value(a.observation_source),\n",
    "                        self._format_value(a.location_in_observation_source),\n",
    "                        self._format_value(a.reconstruction_source),\n",
    "                        self._format_value(a.location_in_reconstruction_source),\n",
    "                        self._format_value(a.comment)\n",
    "                    ])\n",
    "            appellationsFrame = pd.DataFrame(appellationsFrame, \n",
    "                                           columns=['URI', 'Observation', 'Reconstruction', 'Appellation', \n",
    "                                                   'AppellationType', 'AnnotationDate', 'StartDate', 'EndDate',\n",
    "                                                   'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                                   'Toponym', 'Observation source', 'Location in Observation Source', \n",
    "                                                   'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])\n",
    "            appellationsFrame.to_csv('appellations.csv')\n",
    "\n",
    "        if makeActive_as:\n",
    "            activeAsFrame = []\n",
    "            for p in self.persons:\n",
    "                for a in p.active_as:\n",
    "                    activeAsFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(a.observation_id),\n",
    "                        self._format_value(a.reconstruction_id),\n",
    "                        self._format_value(a.original_label),\n",
    "                        self._format_value(a.activity),\n",
    "                        self._format_value(a.activityType),\n",
    "                        self._format_value(a.employer),\n",
    "                        self._format_value(a.location),\n",
    "                        self._format_value(a.annotationDate),\n",
    "                        self._format_value(a.startDate),\n",
    "                        self._format_value(a.endDate),\n",
    "                        self._format_value(a.startDate_min),\n",
    "                        self._format_value(a.startDate_max),\n",
    "                        self._format_value(a.endDate_min),\n",
    "                        self._format_value(a.endDate_max),\n",
    "                        self._format_value(a.observation_source),\n",
    "                        self._format_value(a.location_in_observation_source),\n",
    "                        self._format_value(a.reconstruction_source),\n",
    "                        self._format_value(a.location_in_reconstruction_source),\n",
    "                        self._format_value(a.comment)\n",
    "                    ])\n",
    "            activeAsFrame = pd.DataFrame(activeAsFrame, \n",
    "                                       columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                               'Activity', 'ActivityType', 'Employer', 'Location', \n",
    "                                               'AnnotationDate', 'StartDate', 'EndDate',\n",
    "                                               'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                               'Observation source', 'Location in Observation Source', 'Reconstruction Source', \n",
    "                                               'Location in Reconstruction Source', 'Comment'])\n",
    "            activeAsFrame.to_csv('activities.csv')\n",
    "\n",
    "        if makeIdentities:\n",
    "            identitiesFrame = []\n",
    "            for p in self.persons:\n",
    "                for identity in p.identities:\n",
    "                    identitiesFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(identity.observation_id),\n",
    "                        self._format_value(identity.reconstruction_id),\n",
    "                        self._format_value(identity.original_label),\n",
    "                        self._format_value(identity.identity),\n",
    "                        self._format_value(identity.identityType),\n",
    "                        self._format_value(identity.location),\n",
    "                        self._format_value(identity.annotationDate),\n",
    "                        self._format_value(identity.startDate),\n",
    "                        self._format_value(identity.endDate),\n",
    "                        self._format_value(identity.startDate_min),\n",
    "                        self._format_value(identity.startDate_max),\n",
    "                        self._format_value(identity.endDate_min),\n",
    "                        self._format_value(identity.endDate_max),\n",
    "                        self._format_value(identity.observation_source),\n",
    "                        self._format_value(identity.location_in_observation_source),\n",
    "                        self._format_value(identity.reconstruction_source),\n",
    "                        self._format_value(identity.location_in_reconstruction_source),\n",
    "                        self._format_value(identity.comment)\n",
    "                    ])\n",
    "            identitiesFrame = pd.DataFrame(identitiesFrame, \n",
    "                                         columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                                 'Identity', 'IdentityType', 'Location', 'AnnotationDate', \n",
    "                                                 'StartDate', 'EndDate',\n",
    "                                                 'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                                 'Observation source', 'Location in Observation Source',\n",
    "                                                 'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])\n",
    "            identitiesFrame.to_csv('identities.csv')\n",
    "\n",
    "        if makeStatuses:\n",
    "            statusesFrame = []\n",
    "            for p in self.persons:\n",
    "                for status in p.statuses:\n",
    "                    statusesFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(status.observation_id),\n",
    "                        self._format_value(status.reconstruction_id),\n",
    "                        self._format_value(status.original_label),\n",
    "                        self._format_value(status.status),\n",
    "                        self._format_value(status.statusType),\n",
    "                        self._format_value(status.location),\n",
    "                        self._format_value(status.annotationDate),\n",
    "                        self._format_value(status.startDate),\n",
    "                        self._format_value(status.endDate),\n",
    "                        self._format_value(status.startDate_min),\n",
    "                        self._format_value(status.startDate_max),\n",
    "                        self._format_value(status.endDate_min),\n",
    "                        self._format_value(status.endDate_max),\n",
    "                        self._format_value(status.observation_source),\n",
    "                        self._format_value(status.location_in_observation_source),\n",
    "                        self._format_value(status.reconstruction_source),\n",
    "                        self._format_value(status.location_in_reconstruction_source),\n",
    "                        self._format_value(status.comment)\n",
    "                    ])\n",
    "            statusesFrame = pd.DataFrame(statusesFrame, \n",
    "                                       columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                               'Status', 'StatusType', 'Location', 'AnnotationDate', \n",
    "                                               'StartDate', 'EndDate',\n",
    "                                               'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                               'Observation source', 'Location in Observation Source',\n",
    "                                               'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])\n",
    "            statusesFrame.to_csv('statuses.csv')\n",
    "\n",
    "        if makeLocation_relations:\n",
    "            locationRelationFrame = []\n",
    "            for p in self.persons:\n",
    "                for lr in p.location_relations:\n",
    "                    locationRelationFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(lr.observation_id),\n",
    "                        self._format_value(lr.reconstruction_id),\n",
    "                        self._format_value(lr.original_label),\n",
    "                        self._format_value(lr.locationRelation),\n",
    "                        self._format_value(lr.location),\n",
    "                        self._format_value(lr.annotationDate),\n",
    "                        self._format_value(lr.startDate),\n",
    "                        self._format_value(lr.endDate),\n",
    "                        self._format_value(lr.startDate_min),\n",
    "                        self._format_value(lr.startDate_max),\n",
    "                        self._format_value(lr.endDate_min),\n",
    "                        self._format_value(lr.endDate_max),\n",
    "                        self._format_value(lr.observation_source),\n",
    "                        self._format_value(lr.location_in_observation_source),\n",
    "                        self._format_value(lr.reconstruction_source),\n",
    "                        self._format_value(lr.location_in_reconstruction_source),\n",
    "                        self._format_value(lr.comment)\n",
    "                    ])\n",
    "            locationRelationFrame = pd.DataFrame(locationRelationFrame, \n",
    "                                              columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                                     'LocationRelation', 'Location', 'AnnotationDate', \n",
    "                                                     'StartDate', 'EndDate',\n",
    "                                                     'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                                     'Observation source', 'Location in Observation Source',\n",
    "                                                     'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])\n",
    "            locationRelationFrame.to_csv('locationRelations.csv')\n",
    "\n",
    "        if makeRelations:\n",
    "            relationsFrame = []\n",
    "            for p in self.persons:\n",
    "                for r in p.relations:\n",
    "                    relationsFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(r.observation_id),\n",
    "                        self._format_value(r.reconstruction_id),\n",
    "                        self._format_value(r.original_label),\n",
    "                        self._format_value(r.relation),\n",
    "                        self._format_value(r.otherPerson),\n",
    "                        self._format_value(r.annotationDate),\n",
    "                        self._format_value(r.startDate),\n",
    "                        self._format_value(r.endDate),\n",
    "                        self._format_value(r.startDate_min),\n",
    "                        self._format_value(r.startDate_max),\n",
    "                        self._format_value(r.endDate_min),\n",
    "                        self._format_value(r.endDate_max),\n",
    "                        self._format_value(r.observation_source),\n",
    "                        self._format_value(r.location_in_observation_source),\n",
    "                        self._format_value(r.reconstruction_source),\n",
    "                        self._format_value(r.location_in_reconstruction_source),\n",
    "                        self._format_value(r.comment)\n",
    "                    ])\n",
    "            relationsFrame = pd.DataFrame(relationsFrame, \n",
    "                                       columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                               'Relation', 'OtherPerson', 'AnnotationDate', 'StartDate', \n",
    "                                               'EndDate',\n",
    "                                               'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                               'Observation source', 'Location in Observation Source',\n",
    "                                               'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])     \n",
    "            relationsFrame.to_csv('relations.csv')\n",
    "\n",
    "        if makeEvents:\n",
    "            eventsFrame = []\n",
    "            for p in self.persons:\n",
    "                for e in p.events:\n",
    "                    eventsFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(e.observation_id),\n",
    "                        self._format_value(e.reconstruction_id),\n",
    "                        self._format_value(e.original_label),\n",
    "                        self._format_value(e.event),\n",
    "                        self._format_value(e.argument),\n",
    "                        self._format_value(e.location),\n",
    "                        self._format_value(e.annotationDate),\n",
    "                        self._format_value(e.startDate),\n",
    "                        self._format_value(e.endDate),\n",
    "                        self._format_value(e.startDate_min),\n",
    "                        self._format_value(e.startDate_max),\n",
    "                        self._format_value(e.endDate_min),\n",
    "                        self._format_value(e.endDate_max),\n",
    "                        self._format_value(e.observation_source),\n",
    "                        self._format_value(e.location_in_observation_source),\n",
    "                        self._format_value(e.reconstruction_source),\n",
    "                        self._format_value(e.location_in_reconstruction_source),\n",
    "                        self._format_value(e.comment)\n",
    "                    ])\n",
    "            eventsFrame = pd.DataFrame(eventsFrame, \n",
    "                                     columns=['URI', 'Observation', 'Reconstruction', 'Original Label', \n",
    "                                             'Event', 'Argument', 'Location', 'AnnotationDate', \n",
    "                                             'StartDate', 'EndDate',\n",
    "                                             'StartDate_Min', 'StartDate_Max', 'EndDate_Min', 'EndDate_Max',\n",
    "                                             'Observation source', 'Location in Observation Source',\n",
    "                                             'Reconstruction Source', 'Location in Reconstruction Source', 'Comment'])\n",
    "            eventsFrame.to_csv('events.csv')\n",
    "\n",
    "        if makeExternalReferences:\n",
    "            externalReferencesFrame = []\n",
    "            for p in self.persons:\n",
    "                for ref in p.external_references:\n",
    "                    externalReferencesFrame.append([\n",
    "                        p.URI,\n",
    "                        self._format_value(ref.reconstruction_id),\n",
    "                        self._format_value(ref.external_db_name),\n",
    "                        self._format_value(ref.external_id),\n",
    "                        self._format_value(ref.external_id_type)\n",
    "                    ])\n",
    "            externalReferencesFrame = pd.DataFrame(externalReferencesFrame, \n",
    "                                                columns=['URI', 'Reconstruction ID', 'External DB Name', \n",
    "                                                        'External ID', 'External ID Type'])\n",
    "            externalReferencesFrame.to_csv('external_references.csv')    \n",
    "        \n",
    "    def update_db(self, db, makeOverview=True, makeAppellations=True, makeActive_as=True, \n",
    "                 makeIdentities=True, makeStatuses=True, makeLocation_relations=True, \n",
    "                 makeRelations=True, makeEvents=True, makeExternalReferences=True):\n",
    "\n",
    "        # Create engine\n",
    "        engine = create_engine(f'sqlite:///{db}')\n",
    "        metadata = MetaData(f'sqlite:///{db}')\n",
    "\n",
    "        # Copy the .schema into the metadata\n",
    "        metadata.reflect(bind=engine)\n",
    "\n",
    "        # Create a session with autoflush off\n",
    "        Session = sessionmaker(bind=engine, autoflush=False)\n",
    "        session = Session()\n",
    "\n",
    "        # For each table, check if it needs to be constructed\n",
    "        if makeOverview:\n",
    "            # If so, connect the table to a variable\n",
    "            overview_table = metadata.tables['persons']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class Overview_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(Overview_sql, overview_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                new_overview_sql = Overview_sql()\n",
    "                new_overview_sql.URI = p.URI\n",
    "                new_overview_sql.comment = p.comment\n",
    "                session.merge(new_overview_sql)\n",
    "\n",
    "        if makeAppellations:\n",
    "            # If so, connect the table to a variable\n",
    "            appellation_table = metadata.tables['appellations']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class Appellation_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(Appellation_sql, appellation_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.appellations:\n",
    "                    new_appellation_sql = Appellation_sql()\n",
    "                    new_appellation_sql.URI = p.URI\n",
    "                    new_appellation_sql.observation_id = a.observation_id\n",
    "                    new_appellation_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_appellation_sql.appellation = a.appellation\n",
    "                    new_appellation_sql.appellationType = a.appellationType\n",
    "                    new_appellation_sql.annotationDate = a.annotationDate\n",
    "                    new_appellation_sql.startDate = a.startDate\n",
    "                    new_appellation_sql.endDate = a.endDate\n",
    "                    new_appellation_sql.startDate_min = a.startDate_min\n",
    "                    new_appellation_sql.startDate_max = a.startDate_max\n",
    "                    new_appellation_sql.endDate_min = a.endDate_min\n",
    "                    new_appellation_sql.endDate_max = a.endDate_max\n",
    "                    new_appellation_sql.toponym = a.toponym\n",
    "                    new_appellation_sql.observation_source = a.observation_source\n",
    "                    new_appellation_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_appellation_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_appellation_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_appellation_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_appellation_sql)\n",
    "\n",
    "        if makeActive_as:\n",
    "            # If so, connect the table to a variable\n",
    "            activeAs_table = metadata.tables['activeAs']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class activeAs_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(activeAs_sql, activeAs_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.active_as:\n",
    "                    new_activeAs_sql = activeAs_sql()\n",
    "                    new_activeAs_sql.URI = p.URI\n",
    "                    new_activeAs_sql.observation_id = a.observation_id\n",
    "                    new_activeAs_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_activeAs_sql.original_label = a.original_label\n",
    "                    new_activeAs_sql.activity = a.activity\n",
    "                    new_activeAs_sql.activityType = a.activityType\n",
    "                    new_activeAs_sql.employer = a.employer\n",
    "                    new_activeAs_sql.annotationDate = a.annotationDate\n",
    "                    new_activeAs_sql.startDate = a.startDate\n",
    "                    new_activeAs_sql.endDate = a.endDate\n",
    "                    new_activeAs_sql.startDate_min = a.startDate_min\n",
    "                    new_activeAs_sql.startDate_max = a.startDate_max\n",
    "                    new_activeAs_sql.endDate_min = a.endDate_min\n",
    "                    new_activeAs_sql.endDate_max = a.endDate_max\n",
    "                    new_activeAs_sql.location = a.location\n",
    "                    new_activeAs_sql.observation_source = a.observation_source\n",
    "                    new_activeAs_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_activeAs_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_activeAs_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_activeAs_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_activeAs_sql)\n",
    "\n",
    "        if makeIdentities:\n",
    "            # If so, connect the table to a variable\n",
    "            identities_table = metadata.tables['identities']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class Identity_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(Identity_sql, identities_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.identities:\n",
    "                    new_Identity_sql = Identity_sql()\n",
    "                    new_Identity_sql.URI = p.URI\n",
    "                    new_Identity_sql.observation_id = a.observation_id\n",
    "                    new_Identity_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_Identity_sql.original_label = a.original_label\n",
    "                    new_Identity_sql.identity = a.identity\n",
    "                    new_Identity_sql.identityType = a.identityType\n",
    "                    new_Identity_sql.annotationDate = a.annotationDate\n",
    "                    new_Identity_sql.startDate = a.startDate\n",
    "                    new_Identity_sql.endDate = a.endDate\n",
    "                    new_Identity_sql.startDate_min = a.startDate_min\n",
    "                    new_Identity_sql.startDate_max = a.startDate_max\n",
    "                    new_Identity_sql.endDate_min = a.endDate_min\n",
    "                    new_Identity_sql.endDate_max = a.endDate_max\n",
    "                    new_Identity_sql.location = a.location\n",
    "                    new_Identity_sql.observation_source = a.observation_source\n",
    "                    new_Identity_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_Identity_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_Identity_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_Identity_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_Identity_sql)\n",
    "\n",
    "        if makeStatuses:\n",
    "            # If so, connect the table to a variable\n",
    "            statuses_table = metadata.tables['statuses']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class Status_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(Status_sql, statuses_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.statuses:\n",
    "                    new_Status_sql = Status_sql()\n",
    "                    new_Status_sql.URI = p.URI\n",
    "                    new_Status_sql.observation_id = a.observation_id\n",
    "                    new_Status_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_Status_sql.original_label = a.original_label\n",
    "                    new_Status_sql.status = a.status\n",
    "                    new_Status_sql.statusType = a.statusType\n",
    "                    new_Status_sql.annotationDate = a.annotationDate\n",
    "                    new_Status_sql.startDate = a.startDate\n",
    "                    new_Status_sql.endDate = a.endDate\n",
    "                    new_Status_sql.startDate_min = a.startDate_min\n",
    "                    new_Status_sql.startDate_max = a.startDate_max\n",
    "                    new_Status_sql.endDate_min = a.endDate_min\n",
    "                    new_Status_sql.endDate_max = a.endDate_max\n",
    "                    new_Status_sql.location = a.location\n",
    "                    new_Status_sql.observation_source = a.observation_source\n",
    "                    new_Status_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_Status_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_Status_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_Status_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_Status_sql)      \n",
    "\n",
    "        if makeLocation_relations:\n",
    "            # If so, connect the table to a variable\n",
    "            locationRelations_table = metadata.tables['locationRelations']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class locationRelation_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(locationRelation_sql, locationRelations_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.location_relations:\n",
    "                    new_locationRelation_sql = locationRelation_sql()\n",
    "                    new_locationRelation_sql.URI = p.URI\n",
    "                    new_locationRelation_sql.observation_id = a.observation_id\n",
    "                    new_locationRelation_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_locationRelation_sql.original_label = a.original_label\n",
    "                    new_locationRelation_sql.annotationDate = a.annotationDate\n",
    "                    new_locationRelation_sql.startDate = a.startDate\n",
    "                    new_locationRelation_sql.endDate = a.endDate\n",
    "                    new_locationRelation_sql.startDate_min = a.startDate_min\n",
    "                    new_locationRelation_sql.startDate_max = a.startDate_max\n",
    "                    new_locationRelation_sql.endDate_min = a.endDate_min\n",
    "                    new_locationRelation_sql.endDate_max = a.endDate_max\n",
    "                    new_locationRelation_sql.location = a.location\n",
    "                    new_locationRelation_sql.observation_source = a.observation_source\n",
    "                    new_locationRelation_sql.locationRelation = a.locationRelation\n",
    "                    new_locationRelation_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_locationRelation_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_locationRelation_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_locationRelation_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_locationRelation_sql)   \n",
    "\n",
    "        if makeRelations:\n",
    "            # If so, connect the table to a variable\n",
    "            relations_table = metadata.tables['relations']\n",
    "\n",
    "            # Create an empty object to bind to the table\n",
    "            class relation_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(relation_sql, relations_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.relations:\n",
    "                    new_relation_sql = relation_sql()\n",
    "                    new_relation_sql.URI = p.URI\n",
    "                    new_relation_sql.observation_id = a.observation_id\n",
    "                    new_relation_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_relation_sql.original_label = a.original_label\n",
    "                    new_relation_sql.otherPerson = a.otherPerson\n",
    "                    new_relation_sql.relation = a.relation\n",
    "                    new_relation_sql.annotationDate = a.annotationDate\n",
    "                    new_relation_sql.startDate = a.startDate\n",
    "                    new_relation_sql.endDate = a.endDate\n",
    "                    new_relation_sql.startDate_min = a.startDate_min\n",
    "                    new_relation_sql.startDate_max = a.startDate_max\n",
    "                    new_relation_sql.endDate_min = a.endDate_min\n",
    "                    new_relation_sql.endDate_max = a.endDate_max\n",
    "                    new_relation_sql.observation_source = a.observation_source\n",
    "                    new_relation_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_relation_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_relation_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_relation_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_relation_sql)   \n",
    "\n",
    "        if makeEvents:\n",
    "            events_table = metadata.tables['events']\n",
    "\n",
    "            class event_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(event_sql, events_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.events:\n",
    "                    new_event_sql = event_sql()\n",
    "                    new_event_sql.URI = p.URI\n",
    "                    new_event_sql.observation_id = a.observation_id\n",
    "                    new_event_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_event_sql.original_label = a.original_label\n",
    "                    new_event_sql.event = a.event\n",
    "                    new_event_sql.argument = a.argument\n",
    "                    new_event_sql.annotationDate = a.annotationDate\n",
    "                    new_event_sql.startDate = a.startDate\n",
    "                    new_event_sql.endDate = a.endDate\n",
    "                    new_event_sql.startDate_min = a.startDate_min\n",
    "                    new_event_sql.startDate_max = a.startDate_max\n",
    "                    new_event_sql.endDate_min = a.endDate_min\n",
    "                    new_event_sql.endDate_max = a.endDate_max\n",
    "                    new_event_sql.location = a.location\n",
    "                    new_event_sql.observation_source = a.observation_source\n",
    "                    new_event_sql.location_in_observation_source = a.location_in_observation_source\n",
    "                    new_event_sql.reconstruction_source = a.reconstruction_source\n",
    "                    new_event_sql.location_in_reconstruction_source = a.location_in_reconstruction_source\n",
    "                    new_event_sql.comment = a.comment\n",
    "\n",
    "                    session.merge(new_event_sql)\n",
    "\n",
    "        if makeExternalReferences:\n",
    "            external_references_table = metadata.tables['externalReferences']\n",
    "\n",
    "            class external_reference_sql(object): pass\n",
    "\n",
    "            # Map table to object\n",
    "            mapper(external_reference_sql, external_references_table)\n",
    "\n",
    "            for p in tqdm(self.persons):\n",
    "                for a in p.external_references:\n",
    "                    new_external_reference_sql = external_reference_sql()\n",
    "                    new_external_reference_sql.URI = p.URI\n",
    "                    new_external_reference_sql.reconstruction_id = a.reconstruction_id\n",
    "                    new_external_reference_sql.external_db_name = a.external_db_name\n",
    "                    new_external_reference_sql.external_id = a.external_id\n",
    "                    new_external_reference_sql.external_id_type = a.external_id_type\n",
    "\n",
    "                    session.merge(new_external_reference_sql)\n",
    "\n",
    "        # After all that\n",
    "\n",
    "        # Commit the session after all merges are done\n",
    "        try:\n",
    "            session.commit()\n",
    "        except OperationalError as e:\n",
    "            session.rollback()  # Roll back the transaction on error\n",
    "            print(f\"An error occurred: {e}\")    \n",
    "\n",
    "        session.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14cff74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_linking_list(filename):\n",
    "    #Reads a CSV file and converts it into a dictionary where the 'original_label' is the key and the 'URI' is the value.\n",
    "    result = {}\n",
    "\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "    # Convert the DataFrame into a dictionary\n",
    "    result = dict(zip(df['original_label'].str.strip().str.lower(), df['URI']))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697e657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
